{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Database and table creation\n",
    "\n",
    "In this lab, you will explore the best practices fro IBM DB2 Event Store. You will learn:\n",
    "- Database creation with IBM DB2 Event Store\n",
    "- Best practices for table definition\n",
    "- Best practices for indexing a table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Setting basic import clauses used by this notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from eventstore.oltp import EventContext\n",
    "from eventstore.sql import EventSession\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Setting the IP address to connect to your IBM Db2 Event Store cluster\n",
    "\n",
    "For this, you will need to find out the connection string to your IBM Db2 Event Store cluster.\n",
    "\n",
    "Perform the following steps:\n",
    "\n",
    "- Replace the IP address in the below program code with the public IP address of your local IBM Db2 Event Store one-node host.\n",
    "- Then execute the program cell below. It will override the configuration in the notebook environment to connect to the IBM Db2 Event Store cluster in the provided connection string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint: 9.30.167.102:1101\n"
     ]
    }
   ],
   "source": [
    "from eventstore.common import ConfigurationReader\n",
    "\n",
    "ip = \"9.30.167.102\"\n",
    "\n",
    "endpoint = ip + ':1101'\n",
    "\n",
    "print(\"Endpoint: \"+ endpoint)\n",
    "\n",
    "ConfigurationReader.setConnectionEndpoints(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Opening a database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The following code is used to open a database and populate it with tables and data.\n",
    "Run the command in the next program cell to define the database name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dbName = \"TESTDB\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To run Spark SQL queries, you must set up a Db2 Event Store Spark session. The EventSession class extends the optimizer of the SparkSession class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sparkSession = SparkSession.builder.appName(\"EventStore SQL in Python\").getOrCreate()\n",
    "eventSession = EventSession(sparkSession.sparkContext, dbName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Run the following cell to try to create the database. If the database with same name already exists, we will drop it and create a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    EventContext.create_database(dbName)\n",
    "except:\n",
    "    EventContext.drop_database(dbName)\n",
    "    EventContext.create_database(dbName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now you can execute the command to open the database in the event session you created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "eventSession.open_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Exploring the database by retrieving all tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The following code section retrieves the names of all tables that exist in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event context successfully retrieved.\n"
     ]
    }
   ],
   "source": [
    "with EventContext.get_event_context(dbName) as ctx:\n",
    "   print(\"Event context successfully retrieved.\")\n",
    "\n",
    "table_names = ctx.get_names_of_tables()\n",
    "for idx, name in enumerate(table_names):\n",
    "   print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Creating a table with an index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Like you saw above, there are no tables in the database, we are going to come back to those cells after we create a table to see the table was created. The next cell defined the table name we want to create:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tabName = \"IOT_TEMP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from eventstore.catalog import TableSchema\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "tabSchema = TableSchema(tabName, StructType([\n",
    "    StructField(\"deviceID\", IntegerType(), nullable = False),\n",
    "    StructField(\"sensorID\", IntegerType(), nullable = False),\n",
    "    StructField(\"ts\", LongType(), nullable = False),\n",
    "    StructField(\"ambient_temp\", DoubleType(), nullable = False),\n",
    "    StructField(\"power\", DoubleType(), nullable = False),\n",
    "    StructField(\"temperature\", DoubleType(), nullable = False)\n",
    "    ]),\n",
    "    sharding_columns = [\"deviceID\", \"sensorID\"],\n",
    "    pk_columns = [\"deviceID\", \"sensorID\", \"ts\"]\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "And the following cell defines the index schema that includes two equality columns (deviceID and sensorId), the entries are sorted in timestamp descending order, and includes the reading column to speed up queries that retrieve readings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from eventstore.catalog import IndexSpecification, SortSpecification, ColumnOrder\n",
    "\n",
    "indexSchema = IndexSpecification(\n",
    "          index_name=tabName + \"Index\",\n",
    "          table_schema=tabSchema,\n",
    "          equal_columns = [\"deviceID\", \"sensorID\"],\n",
    "          sort_columns = [\n",
    "            SortSpecification(\"ts\", ColumnOrder.DESCENDING_NULLS_LAST)],\n",
    "          include_columns = [\"temperature\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Finally, the following cell is used to create the table with the index using the create_table_with_index method, passing both the table schema and index schema defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with EventContext.get_event_context(dbName) as ctx:\n",
    "   res = ctx.create_table_with_index(tabSchema,indexSchema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To drop a table we use the drop_table command, like in the cell below, but it is commented out and provided here only as a reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# with EventContext.get_event_context(dbName) as ctx:\n",
    "#     ctx.drop_table(tabName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Loading the tables and inspecting the table schemas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To manipulate or retrieve data from tables you need to load the corresponding tables and get the data frame references to be able to access the tables with your queries. The following code loads all tables and creates a temp view for each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table IOT_TEMP successfully loaded and temp view created.\n"
     ]
    }
   ],
   "source": [
    "table_names = ctx.get_names_of_tables()\n",
    "for tab_name in table_names:\n",
    "    tab = eventSession.load_event_table(tab_name)\n",
    "    tab.createOrReplaceTempView(tab_name)\n",
    "    print(\"Table \"+tab_name+\" successfully loaded and temp view created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Then the following cell can be used to show the schema of the table created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResolvedTableSchema(tableName=IOT_TEMP, schema=StructType(List(StructField(deviceID,IntegerType,false),StructField(sensorID,IntegerType,false),StructField(ts,LongType,false),StructField(ambient_temp,DoubleType,false),StructField(power,DoubleType,false),StructField(temperature,DoubleType,false))), sharding_columns=[u'deviceID', u'sensorID'], pk_columns=[u'deviceID', u'sensorID', u'ts'], partition_columns=None)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    resolved_table_schema = ctx.get_table(tabName)\n",
    "    print(resolved_table_schema)\n",
    "except Exception as err:\n",
    "    print(\"Table not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Summary\n",
    "In this notebook, you learned:\n",
    "- how to connect to a local and remote IBM Db2 Event Store\n",
    "- how to create a new database\n",
    "- how to open a database\n",
    "- how to define a table schema and index schema\n",
    "- how to create a database table with an index\n",
    "- how to list the tables in a database and their schemas\n",
    "\n",
    "### Next Step: Load data into the table\n",
    "With the newly created database and table, you will need to insert some data into the table before starting analysis.\n",
    "To load data into the table, you will have to:\n",
    "- Prepare a sample dataframe stored in an csv file called \"sample_IOT_table.csv\", either use the sample csv file provided under `/data` directory, or generate one using \"generator.py\" script located at the same directory as above.\n",
    "- Run \"load.sh\" to load the data in csv file  \n",
    "(Note: If your Event Store is installed on a Fyre cluster, then the load process should be also executed on an Fyre VM, preferably on the one-node cluster where the Event Store is installed.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2.7 with Watson Studio Spark 2.0.2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
