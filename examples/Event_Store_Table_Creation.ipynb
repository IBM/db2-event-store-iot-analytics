{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database and table creation\n",
    "\n",
    "In this notebook, you will explore the best practices for IBM Db2 Event Store. You will learn:\n",
    "- Database creation with IBM Db2 Event Store\n",
    "- Best practices for table definition\n",
    "- Best practices for indexing a table\n",
    "- How to insert data from a CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to IBM Db2 Event Store\n",
    "\n",
    "### Determine the IP address of your host\n",
    "\n",
    "Obtain the IP address of the host that you want to connect to by running the appropriate command for your operating system:\n",
    "\n",
    "* On Mac, run: `ifconfig`\n",
    "* On Windows, run: `ipconfig`\n",
    "* On Linux, run: `hostname -i`\n",
    "\n",
    "Edit the `HOST = \"XXX.XXX.XXX.XXX\"` value in the next cell to provide the IP address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set your host IP address\n",
    "HOST = \"XXX.XXX.XXX.XXX\"\n",
    "\n",
    "# Port will be 1100 for version 1.1.2 or later (5555 for version 1.1.1)\n",
    "PORT = \"1100\"\n",
    "\n",
    "# Database name\n",
    "DB_NAME = \"TESTDB\"\n",
    "\n",
    "# Table name\n",
    "TABLE_NAME = \"IOT_TEMPERATURE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Python modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from eventstore.common import ConfigurationReader\n",
    "from eventstore.oltp import EventContext\n",
    "from eventstore.sql import EventSession\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Event Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "endpoint = HOST + \":\" + PORT\n",
    "print(\"Event Store connection endpoint:\", endpoint)\n",
    "ConfigurationReader.setConnectionEndpoints(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run Spark SQL queries, you must set up a Db2 Event Store Spark session. The EventSession class extends the optimizer of the SparkSession class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sparkSession = SparkSession.builder.appName(\"EventStore SQL in Python\").getOrCreate()\n",
    "eventSession = EventSession(sparkSession.sparkContext, DB_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the database\n",
    "Run the following cell to try to create the database.\n",
    "\n",
    "> Only one database can be active in Event Store Developer Edition. If you already have a database, you don't need to create one. To create a database in Event Store, you can use the createDatabase function. If you want to drop an existing database to create a new one, use the dropDatabase function first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run this cell if you need to (DROP and/or) CREATE the database.\n",
    "\n",
    "# EventContext.drop_database(DB_NAME)   # Uncomment this if you want to drop an existing database\n",
    "EventContext.create_database(DB_NAME)   # Comment this out (or skip this cell) to re-use an existing database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can execute the command to open the database in the event session you created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eventSession.open_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the database by retrieving all table names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell retrieves and prints the names of all tables in the database.\n",
    "Run it now. You can come back and run it again after you create a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with EventContext.get_event_context(DB_NAME) as ctx:\n",
    "   print(\"Event context successfully retrieved.\")\n",
    "\n",
    "print(\"Table names:\")\n",
    "table_names = ctx.get_names_of_tables()\n",
    "for name in table_names:\n",
    "   print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a table with an index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell defines the schema for the table we want to create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from eventstore.catalog import TableSchema\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "tabSchema = TableSchema(TABLE_NAME, StructType([\n",
    "    StructField(\"deviceID\", IntegerType(), nullable = False),\n",
    "    StructField(\"sensorID\", IntegerType(), nullable = False),\n",
    "    StructField(\"ts\", LongType(), nullable = False),\n",
    "    StructField(\"ambient_temp\", DoubleType(), nullable = False),\n",
    "    StructField(\"power\", DoubleType(), nullable = False),\n",
    "    StructField(\"temperature\", DoubleType(), nullable = False)\n",
    "    ]),\n",
    "    sharding_columns = [\"deviceID\", \"sensorID\"],\n",
    "    pk_columns = [\"deviceID\", \"sensorID\", \"ts\"]\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell defines the index schema which includes two equality columns -- *deviceID* and *sensorId*. The entries are sorted by *timestamp* in descending order. The *temperature* column is included to speed up queries that retrieve temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from eventstore.catalog import IndexSpecification, SortSpecification, ColumnOrder\n",
    "\n",
    "indexSchema = IndexSpecification(\n",
    "          index_name=TABLE_NAME + \"Index\",\n",
    "          table_schema=tabSchema,\n",
    "          equal_columns = [\"deviceID\", \"sensorID\"],\n",
    "          sort_columns = [\n",
    "            SortSpecification(\"ts\", ColumnOrder.DESCENDING_NULLS_LAST)],\n",
    "          include_columns = [\"temperature\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the following cell is used to create the table with the index using the `create_table_with_index()` method, passing both the table schema and the index schema defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with EventContext.get_event_context(DB_NAME) as ctx:\n",
    "   res = ctx.create_table_with_index(tabSchema, indexSchema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To drop a table we use the drop_table command, like in the cell below, but it is commented out and provided here only as a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with EventContext.get_event_context(DB_NAME) as ctx:\n",
    "#     ctx.drop_table(TABLE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the tables and inspect the table schemas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the DataFrame references to be able to access the table with your queries. The following code loads the table and creates a temporary view for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tab = eventSession.load_event_table(TABLE_NAME)\n",
    "tab.createOrReplaceTempView(TABLE_NAME)\n",
    "print(\"Table \" + TABLE_NAME + \" successfully loaded and temporary view created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell can be used to show the schema of the table created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    resolved_table_schema = ctx.get_table(TABLE_NAME)\n",
    "    print(resolved_table_schema)\n",
    "except Exception as err:\n",
    "    print(\"Table \" + TABLE_NAME + \" not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the sample data\n",
    "\n",
    "Let's insert some sample data into the table before starting analysis.\n",
    "To load data into the table, you will have to:\n",
    "\n",
    "- Use the Event Store UI to add the \"sample_IOT_table.csv\" file as a project data asset.\n",
    "- Run the following cells to load the data from **assets**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the CSV into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"assets/sample_IOT_table.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch insert the data from the DataFrame into the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ctx.batch_insert(resolved_table_schema, df.to_records(index=False).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this notebook, you learned how to:\n",
    "- Connect to IBM Db2 Event Store\n",
    "- Create a new database\n",
    "- Open a database\n",
    "- Define a table schema and an index schema\n",
    "- Create a database table with an index\n",
    "- List the tables in a database and their schemas\n",
    "- Insert data into a table from a CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font size=-1 color=gray>\n",
    "&copy; Copyright 2019 IBM Corp. All Rights Reserved.\n",
    "<p>\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file\n",
    "except in compliance with the License. You may obtain a copy of the License at\n",
    "https://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the\n",
    "License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n",
    "express or implied. See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "</font></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
