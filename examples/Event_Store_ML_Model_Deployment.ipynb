{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# IBM Db2 Event Store - Machine Learning Modeling and Model Deployment \n",
    "IBM Db2 Event Store is a hybrid transactional/analytical processing (HTAP) system. This notebook illustrates the machine learning modeling and model deployment using IBM Db2 Event Store.\n",
    "\n",
    "***Pre-Req: Event Store Data Analytics***\n",
    "\n",
    "When finish this demo, you will learn:\n",
    "- How to build a machine learning model\n",
    "- How to save and deploy the model\n",
    "- How to make realtime predictions with the deployed model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to IBM Db2 Event Store\n",
    "\n",
    "### Determine the IP address of your host\n",
    "\n",
    "Obtain the IP address of the host that you want to connect to by running the appropriate command for your operating system:\n",
    "\n",
    "* On Mac, run: `ifconfig`\n",
    "* On Windows, run: `ipconfig`\n",
    "* On Linux, run: `hostname -i`\n",
    "\n",
    "Edit the `HOST = \"XXX.XXX.XXX.XXX\"` value in the next cell to provide the IP address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set your host IP address\n",
    "HOST = \"XXX.XXX.XXX.XXX\"\n",
    "\n",
    "# Port will be 1100 for version 1.1.2 or later (5555 for version 1.1.1)\n",
    "PORT = \"1100\"\n",
    "\n",
    "# Database name\n",
    "DB_NAME = \"TESTDB\"\n",
    "\n",
    "# Table name\n",
    "TABLE_NAME = \"IOT_TEMPERATURE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from eventstore.common import ConfigurationReader\n",
    "from eventstore.oltp import EventContext\n",
    "from eventstore.sql import EventSession\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Event Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event Store connection endpoint: 192.168.0.105:1100\n"
     ]
    }
   ],
   "source": [
    "endpoint = HOST + \":\" + PORT\n",
    "print(\"Event Store connection endpoint:\", endpoint)\n",
    "ConfigurationReader.setConnectionEndpoints(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Open the database\n",
    "\n",
    "The following code is used to open a database to be able to access its tables and data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To run Spark SQL queries, you must set up a Db2 Event Store Spark session. The EventSession class extends the optimizer of the SparkSession class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sparkSession = SparkSession.builder.appName(\"EventStore SQL in Python\").getOrCreate()\n",
    "eventSession = EventSession(sparkSession.sparkContext, DB_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now you can execute the command to open the database in the event session you created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "eventSession.open_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Access an existing table in the database\n",
    "The following code section retrieves the names of all tables that exist in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event context successfully retrieved.\n",
      "Table names:\n",
      "IOT_TEMPERATURE\n"
     ]
    }
   ],
   "source": [
    "with EventContext.get_event_context(DB_NAME) as ctx:\n",
    "   print(\"Event context successfully retrieved.\")\n",
    "\n",
    "print(\"Table names:\")\n",
    "table_names = ctx.get_names_of_tables()\n",
    "for name in table_names:\n",
    "   print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we have the name of the existing table. We then load the table and get a DataFrame references to access the table with queries. The following code loads the tables and creates a temporary view with the same name as the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table IOT_TEMPERATURE successfully loaded and temporary view created.\n"
     ]
    }
   ],
   "source": [
    "tab = eventSession.load_event_table(TABLE_NAME)\n",
    "tab.createOrReplaceTempView(TABLE_NAME)\n",
    "print(\"Table \" + TABLE_NAME + \" successfully loaded and temporary view created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The next code retrieves the schema of the table we want to investigate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResolvedTableSchema(tableName=IOT_TEMPERATURE, schema=StructType(List(StructField(deviceID,IntegerType,false),StructField(sensorID,IntegerType,false),StructField(ts,LongType,false),StructField(ambient_temp,DoubleType,false),StructField(power,DoubleType,false),StructField(temperature,DoubleType,false))), sharding_columns=['deviceID', 'sensorID'], pk_columns=['deviceID', 'sensorID', 'ts'], partition_columns=None)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    resolved_table_schema = ctx.get_table(TABLE_NAME)\n",
    "    print(resolved_table_schema)\n",
    "except Exception as err:\n",
    "    print(\"Table not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Machine Learning Modeling\n",
    "This section shows how to build a machine learning model with the data stored in the IBM Db2 Event Store database.\n",
    "\n",
    "### Recall from the *Event_Store_Data_Analytics* notebook\n",
    "- There are two input variables: ambient temperature and power consumption. The dependent variable is the sensor temperature reading.\n",
    "- All features follow normal distribution.\n",
    "- There is an obvious linear relationship between each independent variable and the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now let's try generating a linear model to predict sensor temperature with power consumption and ambient temperature using the data stored in the IBM Db2 Event Store database table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First import the relevant PySpark machine learning libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler \n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The following cell builds a new spark SQL DataFrame from the `tab` DataFrame, and prints out the `variable_df` DataFrame schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = false)\n",
      " |-- ambient_temp: double (nullable = false)\n",
      " |-- power: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "variables = [\"ambient_temp\", \"power\"]\n",
    "variable_df = tab.select(col(\"temperature\").alias(\"label\"), *variables)\n",
    "variable_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we split the DataFrame into a training set and a test set at a percentage of 75 and 25.\n",
    "\n",
    "We first build and train the model on the training set, then evaluate the model performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "training, test = variable_df.randomSplit([0.75, 0.25], 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The model is built as a pipeline. There are three stages in the model pipeline: *vector assembly*, *standarization*, and *model definition*. \n",
    "\n",
    "In the following cell we execute the three stages.\n",
    "\n",
    "The training set is first assembled in to a dense vector. Then, the dense vector is standarized to a standard normal distribution. Finally, the linear model is defined with regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vectorAssembler = VectorAssembler(inputCols=variables, outputCol=\"unscaled_variables\")\n",
    "standardScaler = StandardScaler(inputCol=\"unscaled_variables\", outputCol=\"features\")\n",
    "linear_model = LinearRegression(maxIter=10, regParam=.01)\n",
    "\n",
    "stages = [vectorAssembler, standardScaler, linear_model]\n",
    "pipeline = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The model is then trained on the training set. The trained model is used to make predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = pipeline.fit(training)\n",
    "prediction = model.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In the following cell we show the first 10 rows out of the approximately 250 thousand in the prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+------------------+--------------------+--------------------+------------------+\n",
      "|             label|      ambient_temp|             power|  unscaled_variables|            features|        prediction|\n",
      "+------------------+------------------+------------------+--------------------+--------------------+------------------+\n",
      "|26.867718317810823|19.000636049568666|  4.69462969258635|[19.0006360495686...|[9.49537135581001...|32.073958640642964|\n",
      "|26.890434961120306| 18.08741047903665|0.5006280784763337|[18.0874104790366...|[9.03899632177425...|28.799124258335304|\n",
      "| 27.24124282274609| 15.64429094179144| 8.926407054969541|[15.6442909417914...|[7.81807260047048...| 29.83167720931017|\n",
      "|28.299657924798513|16.952745077149896| 8.257884674094836|[16.9527450771498...|[8.47195902221244...|31.194962128749516|\n",
      "|28.386549343567314|18.789370305272453|3.9206903754100915|[18.7893703052724...|[9.38979348506817...| 31.41421580790227|\n",
      "|28.553495601501716|17.485530835101855| 7.612154144281628|[17.4855308351018...|[8.73821319452766...|31.563873348664977|\n",
      "|28.617982345819417|19.760802221747348|1.2814043162972304|[19.7608022217473...|[9.87525653850236...|31.358075439850385|\n",
      "|28.764012291412932| 19.24560325013405| 4.679416134125533|[19.2456032501340...|[9.61779118077236...|  32.3840002997382|\n",
      "|28.773582334567948| 17.64604525179404| 6.656609480894468|[17.6460452517940...|[8.81842861418400...| 31.29565095191353|\n",
      "|28.996389903007444|16.700775155045367|6.2617514724941685|[16.7007751550453...|[8.34603965958504...|29.873169188292977|\n",
      "+------------------+------------------+------------------+--------------------+--------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model Evaluation\n",
    "The performance of the linear model we just built can be evaluated using multiple error metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We first load and define a regression evaluator using PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We then evaluate the model performance with multiple error metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rmse = evaluator.evaluate(prediction)\n",
    "\n",
    "mae = evaluator.evaluate(prediction, {evaluator.metricName: \"mae\"})\n",
    "\n",
    "r2 = evaluator.evaluate(prediction, {evaluator.metricName: \"r2\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Finally we put the error metrics into a dataframe to help visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "error_df = {\"r2\":r2, \"mae\":mae, \"rmse\":rmse}\n",
    "error_df = pd.DataFrame.from_dict(error_df, orient=\"index\")\n",
    "error_df.columns = [\"error metrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>1.497963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>1.195381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>0.800141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      error metrics\n",
       "rmse       1.497963\n",
       "mae        1.195381\n",
       "r2         0.800141"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show error metrics\n",
    "error_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Model Summarization**  \n",
    "The r2 metrics shows the percentage of the variance in the data that is explained by the model. Our model has a high r2 value that is very close to 1 -- meaning most of the variance in the test data can be explained with our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model Deployment\n",
    "Now that the model is trained, you can deploy the model. Once deployed, the model can be used to generate real-time online scoring on the data streamed into IBM Db2 Event Store.\n",
    "\n",
    "* If you are using the **Enterprise Edition** of Db2 Event Store, you can use the save function in the `dsx_ml` library.\n",
    "* If you are using the **Developer Edition** of Db2 Event Store, you need to add a Machine Learning service. You can use one with a trial account on IBM Cloud.\n",
    "  * Sign in and create the service [here](https://console.ng.bluemix.net/catalog/services/machine-learning).\n",
    "  * Click on `Service credentials` and then `New credential` and `Add`.\n",
    "  * Use `View credentials` and copy the credentials JSON.\n",
    "  * Use the JSON to set the `wml_credentials` variable below.\n",
    "  * After the pip install watson-machine-learning-client, you may need to restart your kernel and run the notebook again from the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot import dsx_ml. Try using IBM Cloud Machine Learning.\n"
     ]
    }
   ],
   "source": [
    "# This cell will attempt to initialize dsx_ml and set the use_cloud_ml toggle.\n",
    "# Later cells will use the use_cloud_ml toggle, to choose the necessary API.\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "use_cloud_ml = False\n",
    "try:\n",
    "    from dsx_ml.ml import save\n",
    "    if os.environ.get('DSX_TOKEN'):\n",
    "        print('Using dsx_ml to deploy model to IBM Db2 Event Store.')\n",
    "    else:\n",
    "        print('DSX_TOKEN not found, try using IBM Cloud Machine Learning.')\n",
    "        use_cloud_ml = True\n",
    "except ImportError:\n",
    "    print('Cannot import dsx_ml. Try using IBM Cloud Machine Learning.')\n",
    "    use_cloud_ml = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Db2 Event Store Developer Edition plus Machine Learning on IBM Cloud, save the model with metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using IBM Cloud Machine Learning\n",
      "Requirement already satisfied: watson-machine-learning-client==1.0.351 in /home/.local/lib/python3.5/site-packages\n",
      "Requirement already satisfied: ibm-cos-sdk in /home/.local/lib/python3.5/site-packages (from watson-machine-learning-client==1.0.351)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.5/site-packages (from watson-machine-learning-client==1.0.351)\n",
      "Requirement already satisfied: tabulate in /home/.local/lib/python3.5/site-packages (from watson-machine-learning-client==1.0.351)\n",
      "Requirement already satisfied: lomond in /home/.local/lib/python3.5/site-packages (from watson-machine-learning-client==1.0.351)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.5/site-packages (from watson-machine-learning-client==1.0.351)\n",
      "Requirement already satisfied: tqdm in /home/.local/lib/python3.5/site-packages (from watson-machine-learning-client==1.0.351)\n",
      "Requirement already satisfied: urllib3 in /home/.local/lib/python3.5/site-packages (from watson-machine-learning-client==1.0.351)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.5/site-packages (from watson-machine-learning-client==1.0.351)\n",
      "Requirement already satisfied: ibm-cos-sdk-core==2.*,>=2.0.0 in /home/.local/lib/python3.5/site-packages (from ibm-cos-sdk->watson-machine-learning-client==1.0.351)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.5/site-packages (from ibm-cos-sdk->watson-machine-learning-client==1.0.351)\n",
      "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.*,>=2.0.0 in /home/.local/lib/python3.5/site-packages (from ibm-cos-sdk->watson-machine-learning-client==1.0.351)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.5/site-packages (from lomond->watson-machine-learning-client==1.0.351)\n",
      "Requirement already satisfied: python-dateutil>=2 in /opt/conda/lib/python3.5/site-packages (from pandas->watson-machine-learning-client==1.0.351)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.5/site-packages (from pandas->watson-machine-learning-client==1.0.351)\n",
      "Requirement already satisfied: numpy>=1.7.0 in /opt/conda/lib/python3.5/site-packages (from pandas->watson-machine-learning-client==1.0.351)\n",
      "Requirement already satisfied: docutils>=0.10 in /opt/conda/lib/python3.5/site-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk->watson-machine-learning-client==1.0.351)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Model Details:\n",
      "{\n",
      "  \"entity\": {\n",
      "    \"latest_version\": {\n",
      "      \"url\": \"https://us-south.ml.cloud.ibm.com/v3/ml_assets/models/304b0a17-55fd-4ff8-9d02-57ca7cd9e0da/versions/a7793e27-2670-4ad0-8242-a08d60c81363\",\n",
      "      \"guid\": \"a7793e27-2670-4ad0-8242-a08d60c81363\",\n",
      "      \"created_at\": \"2019-01-31T04:15:38.535Z\"\n",
      "    },\n",
      "    \"name\": \"Linear regression model to predict IOT sensor temperature\",\n",
      "    \"evaluation_metrics_url\": \"https://us-south.ml.cloud.ibm.com/v3/wml_instances/9ac1602f-4b7e-4a83-9428-3a3f188acb51/published_models/304b0a17-55fd-4ff8-9d02-57ca7cd9e0da/evaluation_metrics\",\n",
      "    \"tags\": [],\n",
      "    \"deployments\": {\n",
      "      \"url\": \"https://us-south.ml.cloud.ibm.com/v3/wml_instances/9ac1602f-4b7e-4a83-9428-3a3f188acb51/published_models/304b0a17-55fd-4ff8-9d02-57ca7cd9e0da/deployments\",\n",
      "      \"count\": 0\n",
      "    },\n",
      "    \"label_col\": \"label\",\n",
      "    \"learning_configuration_url\": \"https://us-south.ml.cloud.ibm.com/v3/wml_instances/9ac1602f-4b7e-4a83-9428-3a3f188acb51/published_models/304b0a17-55fd-4ff8-9d02-57ca7cd9e0da/learning_configuration\",\n",
      "    \"training_data_schema\": {\n",
      "      \"fields\": [\n",
      "        {\n",
      "          \"nullable\": false,\n",
      "          \"name\": \"label\",\n",
      "          \"type\": \"double\",\n",
      "          \"metadata\": {\n",
      "            \"modeling_role\": \"target\"\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"nullable\": false,\n",
      "          \"name\": \"ambient_temp\",\n",
      "          \"type\": \"double\",\n",
      "          \"metadata\": {}\n",
      "        },\n",
      "        {\n",
      "          \"nullable\": false,\n",
      "          \"name\": \"power\",\n",
      "          \"type\": \"double\",\n",
      "          \"metadata\": {}\n",
      "        }\n",
      "      ],\n",
      "      \"type\": \"struct\"\n",
      "    },\n",
      "    \"feedback_url\": \"https://us-south.ml.cloud.ibm.com/v3/wml_instances/9ac1602f-4b7e-4a83-9428-3a3f188acb51/published_models/304b0a17-55fd-4ff8-9d02-57ca7cd9e0da/feedback\",\n",
      "    \"input_data_schema\": {\n",
      "      \"fields\": [\n",
      "        {\n",
      "          \"nullable\": false,\n",
      "          \"name\": \"ambient_temp\",\n",
      "          \"type\": \"double\",\n",
      "          \"metadata\": {}\n",
      "        },\n",
      "        {\n",
      "          \"nullable\": false,\n",
      "          \"name\": \"power\",\n",
      "          \"type\": \"double\",\n",
      "          \"metadata\": {}\n",
      "        }\n",
      "      ],\n",
      "      \"type\": \"struct\"\n",
      "    },\n",
      "    \"learning_iterations_url\": \"https://us-south.ml.cloud.ibm.com/v3/wml_instances/9ac1602f-4b7e-4a83-9428-3a3f188acb51/published_models/304b0a17-55fd-4ff8-9d02-57ca7cd9e0da/learning_iterations\",\n",
      "    \"model_type\": \"mllib-2.1\",\n",
      "    \"runtime_environment\": \"spark-2.1\"\n",
      "  },\n",
      "  \"metadata\": {\n",
      "    \"url\": \"https://us-south.ml.cloud.ibm.com/v3/wml_instances/9ac1602f-4b7e-4a83-9428-3a3f188acb51/published_models/304b0a17-55fd-4ff8-9d02-57ca7cd9e0da\",\n",
      "    \"guid\": \"304b0a17-55fd-4ff8-9d02-57ca7cd9e0da\",\n",
      "    \"modified_at\": \"2019-01-31T04:15:38.535Z\",\n",
      "    \"created_at\": \"2019-01-31T04:15:38.481Z\"\n",
      "  }\n",
      "}\n",
      "List Models:\n",
      "------------------------------------  ---------------------------------------------------------  ------------------------  ---------\n",
      "GUID                                  NAME                                                       CREATED                   FRAMEWORK\n",
      "304b0a17-55fd-4ff8-9d02-57ca7cd9e0da  Linear regression model to predict IOT sensor temperature  2019-01-31T04:15:38.481Z  mllib-2.1\n",
      "edfb4147-14ca-49e4-8d6e-ef08e0b80d35  Linear regression model to predict IOT sensor temperature  2019-01-31T02:17:50.844Z  mllib-2.1\n",
      "5d2510e6-1dc3-4396-974e-155dc2dd493b  Linear regression model to predict IOT sensor temperature  2019-01-31T02:16:04.156Z  mllib-2.1\n",
      "9e83d0ec-1370-43a3-88cd-294a36d1a15e  Linear regression model to predict IOT sensor temperature  2019-01-24T20:25:19.791Z  mllib-2.1\n",
      "------------------------------------  ---------------------------------------------------------  ------------------------  ---------\n",
      "\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "Synchronous deployment creation for uid: '304b0a17-55fd-4ff8-9d02-57ca7cd9e0da' started\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "\n",
      "INITIALIZING\n",
      "DEPLOY_SUCCESS\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "Successfully finished deployment creation, deployment_uid='6c09d281-e932-4a08-8e87-408a479fcefd'\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Scoring Endpoint:\n",
      "https://us-south.ml.cloud.ibm.com/v3/wml_instances/9ac1602f-4b7e-4a83-9428-3a3f188acb51/deployments/6c09d281-e932-4a08-8e87-408a479fcefd/online\n",
      "List Deployments\n",
      "------------------------------------  -----------------------  ------  --------------  ------------------------  ---------  -------------\n",
      "GUID                                  NAME                     TYPE    STATE           CREATED                   FRAMEWORK  ARTIFACT TYPE\n",
      "6c09d281-e932-4a08-8e87-408a479fcefd  Product line prediction  online  DEPLOY_SUCCESS  2019-01-31T04:15:44.770Z  mllib-2.1  model\n",
      "af6185ad-6525-4604-9d60-521fdf9c5572  Product line prediction  online  DEPLOY_SUCCESS  2019-01-31T02:17:57.111Z  mllib-2.1  model\n",
      "382bc35a-32ba-4a89-9469-14c7bef1d07b  Product line prediction  online  DEPLOY_SUCCESS  2019-01-31T02:16:11.551Z  mllib-2.1  model\n",
      "9520bb90-2a0e-463a-8b48-2d265d66bba6  Product line prediction  online  DEPLOY_SUCCESS  2019-01-24T20:25:28.965Z  mllib-2.1  model\n",
      "------------------------------------  -----------------------  ------  --------------  ------------------------  ---------  -------------\n"
     ]
    }
   ],
   "source": [
    "# If you are using IBM Cloud for your ML deployment...\n",
    "#\n",
    "# * The use_cloud_ml toggle should be set to True.\n",
    "# * You need to set wml_credentials to your service credentials JSON.\n",
    "# * You most likely will need to restart your kernel after running the pip install (below).\n",
    "# * After the pip install runs once, you may want to comment out that line.\n",
    "\n",
    "if use_cloud_ml:\n",
    "    print('Using IBM Cloud Machine Learning')\n",
    "    \n",
    "    !pip install --user watson-machine-learning-client==1.0.351\n",
    "    from watson_machine_learning_client import WatsonMachineLearningAPIClient\n",
    "    \n",
    "    # EDIT HERE TO SET YOUR CREDENTIALS:\n",
    "    wml_credentials = {}\n",
    "    \n",
    "    client = WatsonMachineLearningAPIClient(wml_credentials)\n",
    "    \n",
    "    # Store the model\n",
    "    saved_model = client.repository.store_model(\n",
    "        model=model,\n",
    "        pipeline=pipeline,\n",
    "        training_data=training,\n",
    "        meta_props={client.repository.ModelMetaNames.NAME: \"Linear regression model to predict IOT sensor temperature\"})\n",
    "\n",
    "    published_model_uid = client.repository.get_model_uid(saved_model)\n",
    "    model_details = client.repository.get_details(published_model_uid)\n",
    "    print('Model Details:')\n",
    "    print(json.dumps(model_details, indent=2))\n",
    "    print('List Models:')\n",
    "    client.repository.list_models()\n",
    "\n",
    "    # Create an online deployment\n",
    "    created_deployment = client.deployments.create(published_model_uid, name=\"Product line prediction\")\n",
    "    scoring_endpoint = client.deployments.get_scoring_url(created_deployment)\n",
    "    print('Scoring Endpoint:')\n",
    "    print(scoring_endpoint)\n",
    "    print('List Deployments')\n",
    "    client.deployments.list()\n",
    "    \n",
    "else:\n",
    "    print('Not using remote IBM Cloud Machine Learning.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### With Db2 Event Store Enterprise Edition, save the model with metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "With the saved model we then define a header that contains authorization, which will be sent to the endpoint, and then retrieve the endpoint to the saved model to allow us to externally access it. Note that the host name `dsxl-api` needs to be replaced with the corresponding external IP address of your IBM Watson Studio cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if not use_cloud_ml:\n",
    "    model_name = \"Event_Store_IOT_Sensor_Temperature_Prediction_Model\"\n",
    "    saved_model = save(name=model_name, \n",
    "                       model=model,\n",
    "                       test_data=test,\n",
    "                       algorithm_type=\"Regression\",\n",
    "                       source='Event_Store_Modeling.ipynb',\n",
    "                       description=\"Linear regression model to predict IOT sensor temperature\"\n",
    "                      )\n",
    "\n",
    "    import os\n",
    "    import requests\n",
    "\n",
    "    header_online = {'Content-Type': 'application/json', 'Authorization': os.environ['DSX_TOKEN']}\n",
    "    # Retrieve the endpoint to the saved model\n",
    "    print(saved_model[\"scoring_endpoint\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Make a Prediction with the Deployed Model\n",
    "Now the model has been saved and deployed. After deployment, the endpoint of model can be used to make a prediction for new data using the online scoring service.  \n",
    "\n",
    "The following sample code snippet calls the scoring endpoint to make predictions on the new data. The prediction can be made on single datum, or on batch data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First create a sample datum to be predicted by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create 2 new test data points\n",
    "new_data = {\"deviceID\" : 2, \"sensorID\": 24, \"ts\": 1541430459386, \"ambient_temp\": 30, \"power\": 10}\n",
    "new_data2 = {\"deviceID\" : 1, \"sensorID\": 12, \"ts\": 1541230400000, \"ambient_temp\": 16, \"power\": 50}\n",
    "\n",
    "# Set fields to use for the IBM Cloud Machine Learning API\n",
    "fields = tuple(new_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- Single datum prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"fields\": [\n",
      "    \"ts\",\n",
      "    \"ambient_temp\",\n",
      "    \"deviceID\",\n",
      "    \"power\",\n",
      "    \"sensorID\",\n",
      "    \"unscaled_variables\",\n",
      "    \"features\",\n",
      "    \"prediction\"\n",
      "  ],\n",
      "  \"values\": [\n",
      "    [\n",
      "      1541430459386,\n",
      "      30.0,\n",
      "      2,\n",
      "      10.0,\n",
      "      24,\n",
      "      [\n",
      "        30.0,\n",
      "        10.0\n",
      "      ],\n",
      "      [\n",
      "        14.992189731499383,\n",
      "        3.336760556487845\n",
      "      ],\n",
      "      48.98055760884435\n",
      "    ]\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if use_cloud_ml:\n",
    "    predictions = client.deployments.score(\n",
    "        scoring_endpoint, {\"fields\": tuple(new_data.keys()),\n",
    "                           \"values\": [tuple(new_data.values())]})\n",
    "    print(json.dumps(predictions, indent=2))\n",
    "else:\n",
    "    payload_scoring = [new_data]\n",
    "    scoring_response = requests.post(saved_model[\"scoring_endpoint\"], json=payload_scoring, headers=header_online, verify=False)\n",
    "    print(scoring_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Because this is a regression model, we can retrieve the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions:  [48.98055760884435]\n"
     ]
    }
   ],
   "source": [
    "if use_cloud_ml:\n",
    "    prediction_index = predictions[\"fields\"].index(\"prediction\")\n",
    "    # print(json.dumps(predictions, indent=2))\n",
    "    print(\"predictions: \", [value[prediction_index] for value in predictions[\"values\"]])\n",
    "else:\n",
    "    print(\"predictions: \", scoring_response.json()[\"object\"][\"output\"][\"predictions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- Batch prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions:  [48.98055760884435, 50.76838700137278]\n"
     ]
    }
   ],
   "source": [
    "if use_cloud_ml:\n",
    "    predictions = client.deployments.score(\n",
    "        scoring_endpoint, {\"fields\": tuple(new_data.keys()),\n",
    "                           \"values\": [tuple(new_data.values()),tuple(new_data2.values())]})\n",
    "    # print(json.dumps(predictions, indent=2))\n",
    "    print(\"predictions: \", [value[prediction_index] for value in predictions[\"values\"]])\n",
    "else:\n",
    "    payload_scoring = [new_data, new_data2]\n",
    "    scoring_response = requests.post(saved_model[\"scoring_endpoint\"], json=payload_scoring, headers=header_online, verify=False)\n",
    "    print(scoring_response.text)\n",
    "    print(\"predictions: \", scoring_response.json()[\"object\"][\"output\"][\"predictions\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Summary\n",
    "This notebook introduced you to machine learning and model deployment with IBM Db2 Event Store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font size=-1 color=gray>\n",
    "&copy; Copyright 2019 IBM Corp. All Rights Reserved.\n",
    "<p>\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file\n",
    "except in compliance with the License. You may obtain a copy of the License at\n",
    "https://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the\n",
    "License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n",
    "express or implied. See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "</font></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
