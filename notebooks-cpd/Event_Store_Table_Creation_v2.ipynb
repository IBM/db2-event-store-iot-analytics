{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database and table creation\n",
    "\n",
    "In this notebook, you will explore the best practices for IBM Db2 Event Store. You will learn:\n",
    "- Database creation with IBM Db2 Event Store\n",
    "- Best practices for table definition\n",
    "- Best practices for indexing a table\n",
    "- How to insert data from a CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to IBM Db2 Event Store\n",
    "\n",
    "\n",
    "Edit the values in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CONNECTION_ENDPOINT=\"\"\n",
    "\n",
    "EVENT_USER_ID=\"\"\n",
    "\n",
    "EVENT_PASSWORD=\"\"\n",
    "\n",
    "# Port will be 1100 for version 1.1.2 or later (5555 for version 1.1.1)\n",
    "PORT = \"30370\"\n",
    "\n",
    "DEPLOYMENT_ID=\"\"\n",
    "\n",
    "# Database name\n",
    "DB_NAME = \"EVENTDB\"\n",
    "\n",
    "# Table name\n",
    "TABLE_NAME = \"IOT_TEMPERATURE\"\n",
    "\n",
    "HOSTNAME=\"\"\n",
    "\n",
    "DEPLOYMENT_SPACE=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bearerToken=!echo `curl --silent -k -X GET https://{HOSTNAME}:443/v1/preauth/validateAuth -u {EVENT_USER_ID}:{EVENT_PASSWORD} |python -c \"import sys, json; print(json.load(sys.stdin)['accessToken'])\"`\n",
    "bearerToken=bearerToken[0]\n",
    "keystorePassword=!echo `curl -k --silent  GET -H \"authorization: Bearer {bearerToken}\" \"https://{HOSTNAME}:443/icp4data-databases/{DEPLOYMENT_ID}/zen/com/ibm/event/api/v1/oltp/keystore_password\"`\n",
    "keystorePassword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Python modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: Only run this cell if your IBM Db2 Event Store is installed with IBM Cloud Pak for Data (CP4D)\n",
    "\n",
    "# In IBM Cloud Pak for Data, we need to create link to ensure Event Store Python library is \n",
    "# properly exposed to the Spark runtime.\n",
    "import os\n",
    "src = '/home/spark/user_home/eventstore/eventstore'\n",
    "dst = '/home/spark/shared/user-libs/python3.6/eventstore'\n",
    "try:\n",
    "    os.remove(dst)\n",
    "except EnvironmentError as e:\n",
    "    print(\"Symlink doesn't exist, creating symlink to include Event Store Python library...\")\n",
    "os.symlink(src, dst)\n",
    "print(\"Creating symlink to include Event Store Python library...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eventstore.common import ConfigurationReader\n",
    "from eventstore.oltp import EventContext\n",
    "from eventstore.sql import EventSession\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Event Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfigurationReader.setConnectionEndpoints(CONNECTION_ENDPOINT)\n",
    "ConfigurationReader.setEventUser(EVENT_USER_ID)\n",
    "ConfigurationReader.setEventPassword(EVENT_PASSWORD)\n",
    "ConfigurationReader.setSslKeyAndTrustStorePasswords(keystorePassword[0])\n",
    "ConfigurationReader.setDeploymentID(DEPLOYMENT_ID)\n",
    "ConfigurationReader.getSslTrustStorePassword()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run Spark SQL queries, you must set up a Db2 Event Store Spark session. The EventSession class extends the optimizer of the SparkSession class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkSession = SparkSession.builder.appName(\"EventStore SQL in Python\").getOrCreate()\n",
    "eventSession = EventSession(sparkSession.sparkContext, DB_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the database\n",
    "Run the following cell to try to create the database.\n",
    "\n",
    "> Only one database can be active in Event Store Developer Edition. If you already have a database, you don't need to create one. To create a database in Event Store, you can use the createDatabase function. If you want to drop an existing database to create a new one, use the dropDatabase function first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if you need to (DROP and/or) CREATE the database.\n",
    "\n",
    "# EventContext.drop_database(DB_NAME)   # Uncomment this if you want to drop an existing database\n",
    "# EventContext.create_database(DB_NAME)   # Comment this out (or skip this cell) to re-use an existing database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can execute the command to open the database in the event session you created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventSession.open_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the database by retrieving all table names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell retrieves and prints the names of all tables in the database.\n",
    "Run it now. You can come back and run it again after you create a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with EventContext.get_event_context(DB_NAME) as ctx:\n",
    "   print(\"Event context successfully retrieved.\")\n",
    "    \n",
    "print(\"Table names:\")\n",
    "table_names = ctx.get_names_of_tables()\n",
    "for name in table_names:\n",
    "   print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a table with an index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell defines the schema for the table we want to create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eventstore.catalog import TableSchema\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "tabSchema = TableSchema(TABLE_NAME, StructType([\n",
    "    StructField(\"deviceID\", IntegerType(), nullable = False),\n",
    "    StructField(\"sensorID\", IntegerType(), nullable = False),\n",
    "    StructField(\"ts\", LongType(), nullable = False),\n",
    "    StructField(\"ambient_temp\", DoubleType(), nullable = False),\n",
    "    StructField(\"power\", DoubleType(), nullable = False),\n",
    "    StructField(\"temperature\", DoubleType(), nullable = False)\n",
    "    ]),\n",
    "    sharding_columns = [\"deviceID\", \"sensorID\"],\n",
    "    pk_columns = [\"deviceID\", \"sensorID\", \"ts\"]\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell defines the index schema which includes two equality columns -- *deviceID* and *sensorId*. The entries are sorted by *timestamp* in descending order. The *temperature* column is included to speed up queries that retrieve temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eventstore.catalog import IndexSpecification, SortSpecification, ColumnOrder\n",
    "\n",
    "indexSchema = IndexSpecification(\n",
    "          index_name=TABLE_NAME + \"Index\",\n",
    "          table_schema=tabSchema,\n",
    "          equal_columns = [\"deviceID\", \"sensorID\"],\n",
    "          sort_columns = [\n",
    "            SortSpecification(\"ts\", ColumnOrder.DESCENDING_NULLS_LAST)],\n",
    "          include_columns = [\"temperature\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the following cell is used to create the table with the index using the `create_table_with_index()` method, passing both the table schema and the index schema defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with EventContext.get_event_context(DB_NAME) as ctx:\n",
    "   ctx.drop_table(TABLE_NAME)\n",
    "   res = ctx.create_table_with_index(tabSchema, indexSchema)\n",
    "   print(\"Table names:\")\n",
    "   table_names = ctx.get_names_of_tables()\n",
    "   for name in table_names:\n",
    "      print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To drop a table we use the drop_table command, like in the cell below, but it is commented out and provided here only as a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with EventContext.get_event_context(DB_NAME) as ctx:\n",
    "#     ctx.drop_table(TABLE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this notebook, you learned how to:\n",
    "- Connect to IBM Db2 Event Store\n",
    "- Create a new database\n",
    "- Open a database\n",
    "- Define a table schema and an index schema\n",
    "- Create a database table with an index\n",
    "- List the tables in a database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font size=-1 color=gray>\n",
    "&copy; Copyright 2019 IBM Corp. All Rights Reserved.\n",
    "<p>\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file\n",
    "except in compliance with the License. You may obtain a copy of the License at\n",
    "https://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the\n",
    "License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n",
    "express or implied. See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "</font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 with Spark",
   "language": "python3",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}