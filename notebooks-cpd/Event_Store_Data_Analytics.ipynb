{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBM Db2 Event Store - Data Analytics using Python API \n",
    "\n",
    "IBM Db2 Event Store is a hybrid transactional/analytical processing (HTAP) system. It extends the Spark SQL interface to accelerate analytics queries. \n",
    "\n",
    "This notebook illustrates how the IBM Db2 Event Store can be integrated with multiple popular scientific tools to perform data analytics.\n",
    "\n",
    "***Pre-Req: Event_Store_Table_Creation***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to IBM Db2 Event Store\n",
    "\n",
    "Edit the values in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONNECTION_ENDPOINT=\"\"\n",
    "\n",
    "EVENT_USER_ID=\"\"\n",
    "\n",
    "EVENT_PASSWORD=\"\"\n",
    "\n",
    "# Port will be 1100 for version 1.1.2 or later (5555 for version 1.1.1)\n",
    "PORT = \"30370\"\n",
    "\n",
    "DEPLOYMENT_ID=\"\"\n",
    "\n",
    "# Database name\n",
    "DB_NAME = \"EVENTDB\"\n",
    "\n",
    "# Table name\n",
    "TABLE_NAME = \"IOT_TEMPERATURE\"\n",
    "\n",
    "HOSTNAME=\"\"\n",
    "\n",
    "DEPLOYMENT_SPACE=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bearerToken=!echo `curl --silent -k -X GET https://{HOSTNAME}:443/v1/preauth/validateAuth -u admin:password |python -c \"import sys, json; print(json.load(sys.stdin)['accessToken'])\"`\n",
    "bearerToken=bearerToken[0]\n",
    "keystorePassword=!echo `curl -k --silent  GET -H \"authorization: Bearer {bearerToken}\" \"https://{HOSTNAME}:443/icp4data-databases/{DEPLOYMENT_ID}/zen/com/ibm/event/api/v1/oltp/keystore_password\"`\n",
    "keystorePassword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: Only run this cell if your IBM Db2 Event Store is installed with IBM Cloud Pak for Data (CP4D)\n",
    "\n",
    "# In IBM Cloud Pak for Data, we need to create link to ensure Event Store Python library is \n",
    "# properly exposed to the Spark runtime.\n",
    "import os\n",
    "src = '/home/spark/user_home/eventstore/eventstore'\n",
    "dst = '/home/spark/shared/user-libs/python3.6/eventstore'\n",
    "try:\n",
    "    os.remove(dst)\n",
    "except EnvironmentError as e:\n",
    "    print(\"Symlink doesn't exist, creating symlink to include Event Store Python library...\")\n",
    "os.symlink(src, dst)\n",
    "print(\"Creating symlink to include Event Store Python library...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "\n",
    "from eventstore.common import ConfigurationReader\n",
    "from eventstore.oltp import EventContext\n",
    "from eventstore.sql import EventSession\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from scipy import stats\n",
    "import warnings\n",
    "import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Event Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfigurationReader.setConnectionEndpoints(CONNECTION_ENDPOINT)\n",
    "ConfigurationReader.setEventUser(EVENT_USER_ID)\n",
    "ConfigurationReader.setEventPassword(EVENT_PASSWORD)\n",
    "ConfigurationReader.setSslKeyAndTrustStorePasswords(keystorePassword[0])\n",
    "ConfigurationReader.setDeploymentID(DEPLOYMENT_ID)\n",
    "ConfigurationReader.getSslTrustStorePassword()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the database\n",
    "\n",
    "The cells in this section are used to open the database and create a temporary view for the table that we created previously.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run Spark SQL queries, you must set up a Db2 Event Store Spark session. The EventSession class extends the optimizer of the SparkSession class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkSession = SparkSession.builder.appName(\"EventStore SQL in Python\").getOrCreate()\n",
    "eventSession = EventSession(sparkSession.sparkContext, DB_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can execute the command to open the database in the event session you created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventSession.open_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access an existing table in the database\n",
    "The following code section retrieves the names of all tables that exist in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with EventContext.get_event_context(DB_NAME) as ctx:\n",
    "   print(\"Event context successfully retrieved.\")\n",
    "\n",
    "print(\"Table names:\")\n",
    "table_names = ctx.get_names_of_tables()\n",
    "for name in table_names:\n",
    "   print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the name of the existing table. We then load the corresponding table and get the DataFrame references to access the table with query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = eventSession.load_event_table(TABLE_NAME)\n",
    "print(\"Table \" + TABLE_NAME + \" successfully loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code retrieves the schema of the table we want to investigate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    resolved_table_schema = ctx.get_table(TABLE_NAME)\n",
    "    print(resolved_table_schema)\n",
    "except Exception as err:\n",
    "    print(\"Table not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we create a temporary view with that DataFrame called `readings` that we will use in the queries below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab.createOrReplaceTempView(\"readings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analytics with IBM Db2 Event Store\n",
    "Data analytics tasks can be performed on table stored in the IBM Db2 Event Store database with various data analytics tools. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first take a look at the timestamp range of the record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"SELECT MIN(ts) MIN_TS, MAX(ts) MAX_TS FROM readings\"\n",
    "print(\"{}\\nRunning query in Event Store...\".format(query))\n",
    "df_data = eventSession.sql(query)\n",
    "df_data.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell converts the timestamps in miliseconds to datetime to make it human readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_TS=1541019342393\n",
    "MAX_TS=1541773999825\n",
    "print(\"The time range of the dataset is from {} to {}\".format(\n",
    "    datetime.datetime.fromtimestamp(MIN_TS/1000).strftime('%Y-%m-%d %H:%M:%S'), \n",
    "    datetime.datetime.fromtimestamp(MAX_TS/1000).strftime('%Y-%m-%d %H:%M:%S')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Problem\n",
    "Assume we are only interested in the data recorded by the 12th sensor on the 1st device in the time period on the day of 2018-11-01, and we want to investigate the effects of power consumption and ambient power on the temperature recorded by the sensor in this date.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the timestamp is recorded in milliseconds, we need to convert the datetime of interest to a time range in milliseconds, and then use the range as a filter in the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ts = (datetime.datetime(2018,11,1,0,0) - datetime.datetime(1970,1,1)).total_seconds() * 1000\n",
    "end_ts = (datetime.datetime(2018,11,2,0,0) - datetime.datetime(1970,1,1)).total_seconds() * 1000\n",
    "print(\"The time range of datetime 2018-11-01 in milisec is from {:.0f} to {:.0f}\".format(start_ts, end_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IBM Db2 Event Store extends the Spark SQL functionality, which allows users to apply filters with ease.  \n",
    "\n",
    "In the following cell, the relevant data is extracted according to the problem scope. Note that because we are specifying a specific device and sensor, this query is fully exploiting the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM readings WHERE deviceID=1 AND sensorID=12 AND ts >1541030400000 AND ts < 1541116800000 ORDER BY ts\"\n",
    "print(\"{}\\nRunning query in Event Store...\".format(query))\n",
    "refined_data = eventSession.sql(query)\n",
    "refined_data.createOrReplaceTempView(\"refined_reading\")\n",
    "refined_data.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Statistics \n",
    "For numerical data, knowing the descriptive summary statistics can help a lot in understanding the distribution of the data.\n",
    "\n",
    "IBM Event Store extends the Spark DataFrame functionality. We can use the `describe` function to retrieve statistics about data stored in an IBM Event Store table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_data.describe().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's worth noticing that some power reading records are negative, which may be caused by sensor error. The records with negative power reading will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM readings WHERE deviceID=1 AND sensorID=12 AND ts >1541030400000 AND ts < 1541116800000 AND power > 0 ORDER BY ts\"\n",
    "print(\"{}\\nRunning query in Event Store...\".format(query))\n",
    "refined_data = eventSession.sql(query)\n",
    "refined_data.createOrReplaceTempView(\"refined_reading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of records in the refined table view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT count(*) count FROM refined_reading\"\n",
    "print(\"{}\\nRunning query in Event Store...\".format(query))\n",
    "df_data = eventSession.sql(query)\n",
    "df_data.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance and correlation\n",
    "- Covariance is a measure of how two variables change with respect to each other. It can be examined by calling `.stat.cov()` function on the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "refined_data.stat.cov(\"AMBIENT_TEMP\",\"TEMPERATURE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_data.stat.cov(\"POWER\",\"TEMPERATURE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Correlation is a normalized measure of covariance that is easier to understand, as it provides quantitative measurements of the statistical dependence between two random variables.  It can be examined by calling `.stat.corr()` function on the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_data.stat.corr(\"AMBIENT_TEMP\",\"TEMPERATURE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_data.stat.corr(\"POWER\",\"TEMPERATURE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "Visualization of each feature provides insights into the underlying distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distribution of Ambient Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT ambient_temp FROM refined_reading\"\n",
    "print(\"{}\\nRunning query in Event Store...\".format(query))\n",
    "ambient_temp = eventSession.sql(query)\n",
    "ambient_temp= ambient_temp.toPandas()\n",
    "ambient_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, figsize=(16,6))\n",
    "stats.probplot(ambient_temp.iloc[:,0], plot=plt.subplot(1,3,1))\n",
    "axs[1].boxplot(ambient_temp.iloc[:,0])\n",
    "axs[1].set_title(\"Boxplot on Ambient_temp\")\n",
    "axs[2].hist(ambient_temp.iloc[:,0], bins = 20)\n",
    "axs[2].set_title(\"Histogram on Ambient_temp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distribution of Power Consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT power FROM refined_reading\"\n",
    "print(\"{}\\nRunning query in Event Store...\".format(query))\n",
    "power = eventSession.sql(query)\n",
    "power= power.toPandas()\n",
    "power.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, figsize=(16,6))\n",
    "stats.probplot(power.iloc[:,0], plot=plt.subplot(1,3,1))\n",
    "axs[1].boxplot(power.iloc[:,0])\n",
    "axs[1].set_title(\"Boxplot on Power\")\n",
    "axs[2].hist(power.iloc[:,0], bins = 20)\n",
    "axs[2].set_title(\"Histogram on Power\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distribution of Sensor Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT temperature FROM refined_reading\"\n",
    "print(\"{}\\nRunning query in Event Store...\".format(query))\n",
    "temperature = eventSession.sql(query)\n",
    "temperature= temperature.toPandas()\n",
    "temperature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, figsize=(16,6))\n",
    "stats.probplot(temperature.iloc[:,0], plot=plt.subplot(1,3,1))\n",
    "axs[1].boxplot(temperature.iloc[:,0])\n",
    "axs[1].set_title(\"Boxplot on Temperature\")\n",
    "axs[2].hist(temperature.iloc[:,0], bins = 20)\n",
    "axs[2].set_title(\"Histogram on Temperature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input-variable vs. Target-variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(16,6))\n",
    "axs[0].scatter(power.iloc[:,0], temperature.iloc[:,0])\n",
    "axs[0].set_xlabel(\"power in kW\")\n",
    "axs[0].set_ylabel(\"temperature in celsius\")\n",
    "axs[0].set_title(\"Power vs. Temperature\")\n",
    "axs[1].scatter(ambient_temp.iloc[:,0], temperature.iloc[:,0])\n",
    "axs[1].set_xlabel(\"ambient_temp in celsius\")\n",
    "axs[1].set_ylabel(\"temperature in celsius\")\n",
    "axs[1].set_title(\"Ambient_temp  vs. Temperature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**By observing the plots above, we noticed:**\n",
    "- The distribution of power consumption, ambient temperature, and sensor temperature each follows an roughly normal distribution.\n",
    "- The scatter plot shows the sensor temperature has linear relationships with power consumption and ambient temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Summary\n",
    "This notebook introduced you to data analytics using IBM Db2 Event Store.\n",
    "\n",
    "## Next Step\n",
    "`\"Event_Store_ML_Model_Deployment.ipynb\"` will show you how to build and deploy a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font size=-1 color=gray>\n",
    "&copy; Copyright 2019 IBM Corp. All Rights Reserved.\n",
    "<p>\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file\n",
    "except in compliance with the License. You may obtain a copy of the License at\n",
    "https://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the\n",
    "License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n",
    "express or implied. See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "</font></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 with Spark",
   "language": "python3",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
